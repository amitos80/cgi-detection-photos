# CGI Detection Photos Webservice (Node.js Version)

Based on the research from Professor Farid's website, here is an explanation of how CGI and deepfake detection works, and more importantly, how to interpret a feature_vector in
that context.

How the "CGI or Photo?" Method Works

The core idea behind methods like "CGI or Photo?" is that real photographs and computer-generated images have different statistical fingerprints. Even if they look identical to
the human eye, the underlying pixel patterns and physical properties are different.

Professor Farid's research uses sophisticated techniques to find these hidden statistical patterns. One of the primary methods mentioned is Higher-order Wavelet Statistics.

1. Wavelet Transforms: Think of this as an advanced way to analyze an image. Instead of just looking at pixels, a wavelet transform breaks the image down into different frequency
   and orientation components. This is excellent at revealing subtle textures, noise, and edge patterns that are characteristic of a real camera sensor.
2. Statistical Analysis: After the transform, the method calculates a statistical model of these components. Real photos have a predictable statistical signature because they are
   all captured by physical camera sensors, which have inherent noise and properties. CGI rendering engines produce a different, often "cleaner" or more mathematically perfect,
   statistical signature.
3. Feature Vector: The output of this statistical analysis is a set of numbers—the feature vector. This vector is a compact numerical summary of the image's underlying
   statistical properties.

How to Determine if a Photo is CGI from the Feature Vector

This is the most critical part: a feature vector on its own doesn't tell you anything.

The feature vector must be fed into a Machine Learning (ML) Classifier. Here’s the workflow:

1. Training: Researchers build a massive dataset with thousands of known real photos and thousands of known CGI images.
2. Feature Extraction: They run their wavelet analysis on every single image in the dataset, generating a feature vector for each one.
3. Model Training: They train an ML model (like a Support Vector Machine (SVM) or a neural network) on these feature vectors. The model learns to find the boundary that separates
   the "real photo" vectors from the "CGI" vectors.
4. Classification: Once the model is trained, you can give it a new, unknown image. You extract its feature vector using the exact same wavelet method and feed it to the model.
   The model then outputs a prediction, often a probability score (e.g., "95% probability of being CGI").

Deepfakes vs. CGI

* CGI: An image created from scratch using computer graphics (e.g., a 3D model of a person).
    * Deepfake: An existing photo or video that has been altered, usually by swapping a face.

While both are synthetic, the detection methods can differ. Deepfake detection often looks for artifacts at the boundaries of the swapped face, inconsistencies in head movement,
or unnatural blinking patterns, in addition to the statistical methods used for CGI.

What This Means for Our Current Code

The feature_vector our Node.js server is currently generating is a very basic one (mean, standard deviation, histogram). It is not sophisticated enough to be used for reliable CGI
or deepfake detection. It's a good starting point for image analysis, but it doesn't capture the subtle, high-frequency details that the Berkeley method relies on.

To make our service a true CGI detector, we would need to:

1. Replace `processImageBuffer`: We would need to find or implement a library that can perform wavelet transforms and extract the specific statistical features described in
   Professor Farid's research.
2. Obtain a Trained Model: We would need a pre-trained ML model that knows how to interpret these specific feature vectors. Without it, the vector is just a list of numbers.
   █
   In summary, the feature_vector is the key, but it's only meaningful when generated by a highly specialized algorithm and interpreted by a trained machine learning model.

This is a Node.js webservice for detecting CGI in photos.

## Prerequisites

*   Node.js (v18 or later)
*   npm

## Installation

1.  Navigate to the `webservice` directory:
    ```bash
    cd webservice
    ```
2.  Install the dependencies:
    ```bash
    npm install
    ```

## Building the Application

To compile the TypeScript code to JavaScript, run:

```bash
npm run build
```

This will output the compiled JavaScript files to the `dist` directory.

## Running the Application

To start the server (using `ts-node` for development), run the following command:

```bash
npm start
```

The server will start on `http://localhost:8000`.

## Running Tests

To run the unit tests, use:

```bash
npm test
```

## API Endpoints

*   `GET /`: Serves the main HTML page (`static/index.html`).
*   `POST /analyze`: Accepts an image file upload, analyzes it, and returns a feature vector.
    *   **Method:** `POST`
    *   **Endpoint:** `/analyze`
    *   **Content-Type:** `multipart/form-data`
    *   **Form Field:** `file` (for the image file)
    *   **Response:** JSON object containing `filename` and `feature_vector` (an array of numbers).

## Building and Running with Docker

1.  Navigate to the `webservice` directory.
2.  Build the Docker image:
    ```bash
    docker build -t cgi-detection-webservice .
    ```
3.  Run the Docker container:
    ```bash
    docker run -p 8000:8000 cgi-detection-webservice
    ```

The application will be accessible at `http://localhost:8000`.
