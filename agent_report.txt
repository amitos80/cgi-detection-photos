Agent Execution Log
-------------------
Loaded Context (for LLM):
--- START OF FILE: AGENTS.md ---

# AI Agents Project Instructions

You are the primary Gemini assistant for this repository. Your mission is to strictly enforce the following vendor-neutral project documents:

1.  **Project Rules (Mandatory):** **[./RULES_OF_ENGAGEMENT.md]**
2.  **Common Rules For All Projects:** See **[./COMMON_RULES.md]** for basic strict rules (e.g., NEVER use `git push --force` on the main branch). 
3.  **Security Policy:** See **[./SECURITY.md]** for security rules.
4.  **Behavioral Mandate:** Always review the files above before starting a task.
5.  **Development PLAN is always in:**[./DEVELOPMENT_PLAN.md]**
6.  **All relevant online resources are always in:**[./RESOURCES.md]**
6.  **Current TASK is always in:**[./CURRENT_TASK.md]**


--- END OF FILE: AGENTS.md ---


--- START OF FILE: COMMON_RULES.md ---

# Common Rules For All Projects Must Be Enforced

This project is a full-stack web application with TypeScript frontend and Node.js backend.
The core functionality lives in the `src/` folder, with separate client (`client/`)
and server (`server/`) components.

## Build & Commands

- Typecheck and lint everything: `pnpm check`
- Fix linting/formatting: `pnpm check:fix`
- Run tests: `pnpm test --run --no-color`
- Run single test: `pnpm test --run src/file.test.ts`
- Start development server: `pnpm dev`
- Build for production: `pnpm build`
- Preview production build: `pnpm preview`

### Development Environment

- Frontend dev server: http://localhost:3000
- Backend dev server: http://localhost:3001
- Database runs on port 5432
- Redis cache on port 6379

## Code Style

- TypeScript: Strict mode with exactOptionalPropertyTypes, noUncheckedIndexedAccess
- Tabs for indentation (2 spaces for YAML/JSON/MD)
- Single quotes, no semicolons, trailing commas
- Use JSDoc docstrings for documenting TypeScript definitions, not `//` comments
- 100 character line limit
- Imports: Use consistent-type-imports
- Use descriptive variable/function names
- In CamelCase names, use "URL" (not "Url"), "API" (not "Api"), "ID" (not "Id")
- Prefer functional programming patterns
- Use TypeScript interfaces for public APIs
- NEVER use `@ts-expect-error` or `@ts-ignore` to suppress type errors
- Maximum number of lines in a files is 200 (extract parts to other file or split file if needed)

## Testing

- Vitest for unit testing
- Testing Library for component tests
- Playwright for E2E tests
- When writing tests, do it one test case at a time
- Use `expect(VALUE).toXyz(...)` instead of storing in variables
- Omit "should" from test names (e.g., `it("validates input")` not `it("should validate input")`)
- Test files: `*.test.ts` or `*.spec.ts`
- Mock external dependencies appropriately

## Architecture

- Frontend: React with TypeScript
- Backend: Express.js with TypeScript
- Database: PostgreSQL with Prisma ORM
- State management: Zustand
- Styling: Tailwind CSS
- Build tool: Vite
- Package manager: pnpm

## AI

- For AI-related development, especially for Retrieval-Augmented Generation (RAG), refer to the chunking strategy guidelines in [CHUNKING.md](./CHUNKING.md).

## Security

- Use appropriate data types that limit exposure of sensitive information
- Never commit secrets or API keys to repository
- Use environment variables for sensitive data
- Validate all user inputs on both client and server
- Use HTTPS in production
- Regular dependency updates
- Follow principle of least privilege

## Git Workflow

- ALWAYS run `pnpm check` before committing
- Fix linting errors with `pnpm check:fix`
- Run `pnpm build` to verify typecheck passes
- NEVER use `git push --force` on the main branch
- Use `git push --force-with-lease` for feature branches if needed
- Always verify current branch before force operations

## Configuration

When adding new configuration options, update all relevant places:
1. Environment variables in `.env.example`
2. Configuration schemas in `src/config/`
3. Documentation in README.md

All configuration keys use consistent naming and MUST be documented.


--- END OF FILE: COMMON_RULES.md ---


--- START OF FILE: RULES_OF_ENGAGEMENT.md ---

# The Developer's Pact: Our Core Project Standards
_This document outlines the core principles and conventions we will follow in this project. All AI assistants and human developers must adhere to these rules for building high-quality, maintainable software._

### üèõÔ∏è Principle 1: Architecture & Structure
- **Modularity is Key:** No single file should exceed 500 lines. If it grows too large, your first step is to propose a refactoring plan to break it into smaller, logical modules.
- **Consistent Organization:** We group files by feature. For example, a new `user` feature would have its logic in `src/users/`, its API routes in `src/api/routes/users.py`, and its tests in `tests/users/`.
- **Clean Imports:** Use absolute imports for clarity (e.g., `from src.utils import helpers`). Avoid circular dependencies.
- **Environment First:** All sensitive keys, API endpoints, or configuration variables must be managed through a `.env` file and loaded using `python-dotenv`. Never hardcode them.

### ‚úÖ Principle 2: Quality & Reliability
- **Test Everything That Matters:** Every new function, class, or API endpoint must be accompanied by unit tests in the `tests/` directory.
- **The Test Triad:** For each feature, provide at least three tests:
    1. A "happy path" test for expected behavior.
    2. An "edge case" test for unusual but valid inputs.
    3. A "failure case" test for expected errors or invalid inputs.
- **Docstrings are Non-Negotiable:** Every function must have a Google-style docstring explaining its purpose, arguments (`Args:`), and return value (`Returns:`).

### ‚úçÔ∏è Principle 3: Code & Style
- **Follow the Standards:** All Python code must be formatted with `black` and adhere to `PEP8` guidelines.
- **Type Safety:** Use type hints for all function signatures and variables. We use `mypy` to enforce this.
- **Data Certainty:** Use **`pydantic`** for all data validation, especially for API request and response models. This is our single source of truth for data shapes.

### üß† Principle 4: Your Behavior as an Assistant
- **Clarify, Don't Assume:** If a requirement is ambiguous or context is missing, your first action is to ask for clarification.
- **No Hallucinations:** Do not invent libraries, functions, or file paths.
- **Plan Before You Code:** For any non-trivial task, first outline your implementation plan in a list or with pseudocode.
- **Explain the "Why":** For complex or non-obvious blocks of code, add a `# WHY:` comment explaining the reasoning behind the implementation choice.


--- END OF FILE: RULES_OF_ENGAGEMENT.md ---


--- START OF FILE: DEVELOPMENT_PLAN.md ---

# Development Plan: Improving CGI Detection Accuracy

## 1. Executive Summary

The current CGI detection engine relies on a collection of forensic analysis algorithms, the outputs of which are combined using a hardcoded, weighted-average formula. While this provides a solid baseline, it has significant limitations in accuracy and adaptability, as the weights are not empirically optimized and cannot capture complex relationships between features.

This plan outlines a strategic, phased approach to evolve the system from a heuristic-based model to a data-driven, machine learning-powered solution. By systematically curating a dataset, establishing a rigorous evaluation framework, and incrementally integrating more sophisticated models, we can significantly improve the accuracy, reliability, and robustness of our CGI detection capabilities.

---

## Phase 1: Foundational Setup - Data Curation & Baseline Evaluation

**Goal:** To establish a standardized dataset and an evaluation framework to measure the performance of the current system and all future improvements. We cannot improve what we cannot measure.

**Tasks:**

1.  **Dataset Curation:**
    *   **Action:** Assemble a diverse and balanced dataset of images.
    *   **Requirements:**
        *   **Real Images:** Minimum 5,000 high-quality photographs from various sources (e.g., personal photos, stock images).
        *   **CGI Images:** Minimum 5,000 CGI images covering different categories:
            *   3D Renders (e.g., architectural visualizations, product mockups).
            *   Video Game Screenshots.
            *   AI-Generated Images (e.g., from Stable Diffusion, Midjourney, DALL-E).
            *   Composited images (photo-realistic CGI mixed with real elements).
    *   **Structure:** Organize the dataset into a clear directory structure, such as `/dataset/train/real`, `/dataset/train/cgi`, `/dataset/test/real`, etc.

2.  **Create an Evaluation Script (`evaluate.py`):**
    *   **Action:** Develop a Python script that iterates through the test portion of the curated dataset.
    *   **Functionality:**
        *   For each image, it will call the existing `cgi-detector-service/forensics/engine.py`'s `run_analysis` function.
        *   It will compare the model's prediction (`cgi` or `real`) against the ground truth label.
        *   It will calculate and report key performance metrics:
            *   Accuracy
            *   Precision
            *   Recall
            *   F1-Score
            *   Confusion Matrix
    *   **Outcome:** This script will provide a quantitative baseline for the current system's performance.

---

## Phase 2: Integrating a Machine Learning Classifier

**Goal:** To replace the simple weighted-average logic with a trained machine learning model that can learn the optimal way to combine the existing forensic features.

**Tasks:**

1.  **Develop a Feature Extraction Pipeline:**
    *   **Action:** Create a script that runs every image in the dataset through the individual forensic analysis functions (`ela`, `cfa`, `hos`, etc.).
    *   **Output:** Generate a CSV or Parquet file containing the extracted features (scores) for each image, along with its ground truth label. This will be our training data.

2.  **Train a Classifier Model:**
    *   **Action:** Use the generated feature set to train a classical machine learning model.
    *   **Tools:** Utilize `scikit-learn` or `XGBoost`.
    *   **Process:**
        *   Load the feature dataset.
        *   Split the data into training and validation sets.
        *   Train several candidate models (e.g., `RandomForestClassifier`, `GradientBoostingClassifier`, `SVC`).
        *   Perform hyperparameter tuning to find the best-performing model.
        *   Save the trained model artifact (e.g., using `joblib` or `pickle`).

3.  **Integrate the Trained Model into the Engine:**
    *   **Action:** Modify `cgi-detector-service/forensics/engine.py`.
    *   **Changes:**
        *   Load the saved ML model during application startup.
        *   In `run_analysis`, after collecting all the individual forensic scores, feed them into the loaded model.
        *   The model's output will now be the final prediction and confidence score, replacing the weighted average and heuristic rules.

---

## Phase 3: Advanced Deep Learning for End-to-End Detection

**Goal:** To implement a state-of-the-art deep learning model that can learn features directly from image pixels, potentially outperforming the handcrafted forensic feature set.

**Tasks:**

1.  **Research and Select a CNN Architecture:**
    *   **Action:** Investigate common and effective Convolutional Neural Network (CNN) architectures for image classification.
    *   **Candidates:** `ResNet50`, `EfficientNetV2`, `ConvNeXt`.
    *   **Decision Criteria:** Balance performance, model size, and inference speed.

2.  **Develop a Deep Learning Training Pipeline:**
    *   **Action:** Create a new set of scripts for training the CNN.
    *   **Tools:** Use a deep learning framework like `PyTorch` or `TensorFlow/Keras`.
    *   **Functionality:**
        *   Data loaders for the image dataset with appropriate augmentations (e.g., flips, rotations, color jitter) to improve model robustness.
        *   A training loop that implements backpropagation, optimization, and learning rate scheduling.
        *   Validation loop to monitor performance and prevent overfitting.
        *   Save the best-performing model weights.

3.  **Integrate the CNN Model:**
    *   **Action:** The trained CNN can be integrated in two ways:
        1.  **As a Standalone Predictor:** It can replace the entire Phase 2 ensemble, providing the final prediction directly.
        2.  **As a Feature Extractor:** The CNN's prediction score can be added as a new, powerful feature to the Phase 2 model, allowing the classifier to weigh the CNN's opinion against the traditional forensic signals.
    *   **Implementation:** Create a new module (`cnn_detector.py`) and incorporate it into the main `engine.py`.

---

## Phase 4: Continuous Improvement & Deployment

**Goal:** To ensure the detection model remains accurate and up-to-date with the evolving landscape of CGI and AI-generated imagery.

**Tasks:**

1.  **Continuous Dataset Augmentation:**
    *   **Action:** Develop a process for regularly adding new, challenging, and diverse images to the dataset.
    *   **Source:** Actively seek out images created with the latest generative models and rendering techniques.

2.  **Model Retraining and Monitoring:**
    *   **Action:** Establish a CI/CD pipeline for periodically retraining the models (both the classic classifier and the CNN) on the augmented dataset.
    *   **Monitoring:** Implement logging to track model predictions and confidence scores in a production environment. This can help identify performance degradation or concept drift over time.

--- END OF FILE: DEVELOPMENT_PLAN.md ---


--- START OF FILE: CURRENT_TASK.md ---

# Plan: Add New Features to CGI Detection Algorithm

## Objective

This plan outlines the addition of new forensic features to the CGI detection algorithm. The proposed features are based on techniques and concepts derived from the provided research sources and are intended to enhance the algorithm's accuracy and sophistication.



## Next Steps:

All core features are complete. Future enhancements could include:
- Fine-tuning weights based on empirical testing
- Adding more specialized detectors for specific CGI types
- Machine learning integration for adaptive weight adjustment
- Performance optimizations for faster analysis


--- END OF FILE: CURRENT_TASK.md ---



--- LLM Response / Agent Action would be appended here ---